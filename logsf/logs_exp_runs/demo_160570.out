/ext3/miniconda3/bin:/ext3/miniconda3/bin:/ext3/miniconda3/condabin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/scratch/rss9311/pytorch-env-dir/simvpOpenStl
loading config from /scratch/rss9311/pytorch-env-dir/simvpOpenStl/configs/movingphy/simvp/SimVP_gSTA.py ...
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> training <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Use non-distributed mode with GPU: cuda:0
Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]
CUDA available: True
CUDA_HOME: /usr/local/cuda
NVCC: Build cuda_11.7.r11.7/compiler.31442593_0
GPU 0,1: Tesla V100-SXM2-16GB
GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0
PyTorch: 2.0.1
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.16.1+cu121
OpenCV: 4.7.0
openstl: 0.3.0
------------------------------------------------------------


device: 	cuda	
dist: 	False	
display_step: 	10	
res_dir: 	work_dirs	
ex_name: 	exp_0612_8_am	
use_gpu: 	True	
fp16: 	False	
torchscript: 	False	
seed: 	42	
diff_seed: 	False	
fps: 	False	
empty_cache: 	True	
find_unused_parameters: 	False	
broadcast_buffers: 	True	
resume_from: 	None	
auto_resume: 	False	
test: 	False	
inference: 	False	
deterministic: 	False	
launcher: 	none	
local_rank: 	0	
port: 	29500	
batch_size: 	4	
val_batch_size: 	4	
num_workers: 	4	
data_root: 	/scratch/rss9311/squashfs-root/dataset	
dataname: 	movingphy	
pre_seq_length: 	11	
aft_seq_length: 	11	
total_length: 	22	
use_augment: 	False	
use_prefetcher: 	False	
drop_last: 	False	
method: 	simvp	
config_file: 	/scratch/rss9311/pytorch-env-dir/simvpOpenStl/configs/movingphy/simvp/SimVP_gSTA.py	
model_type: 	gSTA	
drop: 	0.0	
drop_path: 	0	
overwrite: 	False	
epoch: 	50	
log_step: 	1	
opt: 	adam	
opt_eps: 	None	
opt_betas: 	None	
momentum: 	0.9	
weight_decay: 	0.0	
clip_grad: 	None	
clip_mode: 	norm	
early_stop_epoch: 	-1	
no_display_method_info: 	False	
sched: 	onecycle	
lr: 	0.001	
lr_k_decay: 	1.0	
warmup_lr: 	1e-05	
min_lr: 	1e-06	
final_div_factor: 	10000.0	
warmup_epoch: 	0	
decay_epoch: 	100	
decay_rate: 	0.1	
filter_bias_and_bn: 	False	
spatio_kernel_enc: 	3	
spatio_kernel_dec: 	3	
hid_S: 	64	
hid_T: 	512	
N_T: 	8	
N_S: 	4	
in_shape: 	[11, 3, 160, 240]	
metrics: 	['mse', 'mae', 'ssim']	
Model info:
SimVP_Model(
  (enc): Encoder(
    (enc): Sequential(
      (0): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)
          (act): SiLU()
        )
      )
      (1): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)
          (act): SiLU()
        )
      )
      (2): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)
          (act): SiLU()
        )
      )
      (3): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)
          (act): SiLU()
        )
      )
    )
  )
  (dec): Decoder(
    (dec): Sequential(
      (0): ConvSC(
        (conv): BasicConv2d(
          (conv): Sequential(
            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)
          (act): SiLU()
        )
      )
      (1): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)
          (act): SiLU()
        )
      )
      (2): ConvSC(
        (conv): BasicConv2d(
          (conv): Sequential(
            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): PixelShuffle(upscale_factor=2)
          )
          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)
          (act): SiLU()
        )
      )
      (3): ConvSC(
        (conv): BasicConv2d(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm): GroupNorm(2, 64, eps=1e-05, affine=True)
          (act): SiLU()
        )
      )
    )
    (readout): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))
  )
  (hid): MidMetaNet(
    (enc): Sequential(
      (0): MetaBlock(
        (block): GASubBlock(
          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): SpatialAttention(
            (proj_1): Conv2d(704, 704, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): AttentionModule(
              (conv0): Conv2d(704, 704, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=704)
              (conv_spatial): Conv2d(704, 704, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=704)
              (conv1): Conv2d(704, 1408, kernel_size=(1, 1), stride=(1, 1))
            )
            (proj_2): Conv2d(704, 704, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.010)
          (norm2): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(704, 5632, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(5632, 5632, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=5632)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(5632, 704, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (reduction): Conv2d(704, 512, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): MetaBlock(
        (block): GASubBlock(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): SpatialAttention(
            (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): AttentionModule(
              (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
              (conv_spatial): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=512)
              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.009)
          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(512, 4096, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4096)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(4096, 512, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (2): MetaBlock(
        (block): GASubBlock(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): SpatialAttention(
            (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): AttentionModule(
              (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
              (conv_spatial): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=512)
              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.007)
          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(512, 4096, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4096)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(4096, 512, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (3): MetaBlock(
        (block): GASubBlock(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): SpatialAttention(
            (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): AttentionModule(
              (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
              (conv_spatial): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=512)
              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.006)
          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(512, 4096, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4096)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(4096, 512, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (4): MetaBlock(
        (block): GASubBlock(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): SpatialAttention(
            (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): AttentionModule(
              (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
              (conv_spatial): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=512)
              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.004)
          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(512, 4096, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4096)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(4096, 512, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (5): MetaBlock(
        (block): GASubBlock(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): SpatialAttention(
            (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): AttentionModule(
              (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
              (conv_spatial): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=512)
              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.003)
          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(512, 4096, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4096)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(4096, 512, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (6): MetaBlock(
        (block): GASubBlock(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): SpatialAttention(
            (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): AttentionModule(
              (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
              (conv_spatial): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=512)
              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): DropPath(drop_prob=0.001)
          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(512, 4096, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4096)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(4096, 512, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (7): MetaBlock(
        (block): GASubBlock(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (attn): SpatialAttention(
            (proj_1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (activation): GELU(approximate='none')
            (spatial_gating_unit): AttentionModule(
              (conv0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
              (conv_spatial): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(9, 9), dilation=(3, 3), groups=512)
              (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (proj_2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (drop_path): Identity()
          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (mlp): MixMlp(
            (fc1): Conv2d(512, 4096, kernel_size=(1, 1), stride=(1, 1))
            (dwconv): DWConv(
              (dwconv): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4096)
            )
            (act): GELU(approximate='none')
            (fc2): Conv2d(4096, 512, kernel_size=(1, 1), stride=(1, 1))
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (reduction): Conv2d(512, 704, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
)
| module                           | #parameters or shape   | #flops     |
|:---------------------------------|:-----------------------|:-----------|
| model                            | 48.568M                | 0.164T     |
|  enc.enc                         |  0.113M                |  9.7G      |
|   enc.enc.0.conv                 |   1.92K                |   0.865G   |
|    enc.enc.0.conv.conv           |    1.792K              |    0.73G   |
|    enc.enc.0.conv.norm           |    0.128K              |    0.135G  |
|   enc.enc.1.conv                 |   37.056K              |   3.927G   |
|    enc.enc.1.conv.conv           |    36.928K             |    3.893G  |
|    enc.enc.1.conv.norm           |    0.128K              |    33.792M |
|   enc.enc.2.conv                 |   37.056K              |   3.927G   |
|    enc.enc.2.conv.conv           |    36.928K             |    3.893G  |
|    enc.enc.2.conv.norm           |    0.128K              |    33.792M |
|   enc.enc.3.conv                 |   37.056K              |   0.982G   |
|    enc.enc.3.conv.conv           |    36.928K             |    0.973G  |
|    enc.enc.3.conv.norm           |    0.128K              |    8.448M  |
|  dec                             |  0.37M                 |  39.347G   |
|   dec.dec                        |   0.37M                |   39.266G  |
|    dec.dec.0.conv                |    0.148M              |    3.927G  |
|    dec.dec.1.conv                |    37.056K             |    3.927G  |
|    dec.dec.2.conv                |    0.148M              |    15.707G |
|    dec.dec.3.conv                |    37.056K             |    15.707G |
|   dec.readout                    |   0.195K               |   81.101M  |
|    dec.readout.weight            |    (3, 64, 1, 1)       |            |
|    dec.readout.bias              |    (3,)                |            |
|  hid.enc                         |  48.085M               |  0.115T    |
|   hid.enc.0                      |   10.396M              |   24.908G  |
|    hid.enc.0.block               |    10.036M             |    24.043G |
|    hid.enc.0.reduction           |    0.361M              |    0.865G  |
|   hid.enc.1.block                |   5.332M               |   12.767G  |
|    hid.enc.1.block.layer_scale_1 |    (512,)              |            |
|    hid.enc.1.block.layer_scale_2 |    (512,)              |            |
|    hid.enc.1.block.norm1         |    1.024K              |    2.458M  |
|    hid.enc.1.block.attn          |    1.09M               |    2.608G  |
|    hid.enc.1.block.norm2         |    1.024K              |    2.458M  |
|    hid.enc.1.block.mlp           |    4.24M               |    10.155G |
|   hid.enc.2.block                |   5.332M               |   12.767G  |
|    hid.enc.2.block.layer_scale_1 |    (512,)              |            |
|    hid.enc.2.block.layer_scale_2 |    (512,)              |            |
|    hid.enc.2.block.norm1         |    1.024K              |    2.458M  |
|    hid.enc.2.block.attn          |    1.09M               |    2.608G  |
|    hid.enc.2.block.norm2         |    1.024K              |    2.458M  |
|    hid.enc.2.block.mlp           |    4.24M               |    10.155G |
|   hid.enc.3.block                |   5.332M               |   12.767G  |
|    hid.enc.3.block.layer_scale_1 |    (512,)              |            |
|    hid.enc.3.block.layer_scale_2 |    (512,)              |            |
|    hid.enc.3.block.norm1         |    1.024K              |    2.458M  |
|    hid.enc.3.block.attn          |    1.09M               |    2.608G  |
|    hid.enc.3.block.norm2         |    1.024K              |    2.458M  |
|    hid.enc.3.block.mlp           |    4.24M               |    10.155G |
|   hid.enc.4.block                |   5.332M               |   12.767G  |
|    hid.enc.4.block.layer_scale_1 |    (512,)              |            |
|    hid.enc.4.block.layer_scale_2 |    (512,)              |            |
|    hid.enc.4.block.norm1         |    1.024K              |    2.458M  |
|    hid.enc.4.block.attn          |    1.09M               |    2.608G  |
|    hid.enc.4.block.norm2         |    1.024K              |    2.458M  |
|    hid.enc.4.block.mlp           |    4.24M               |    10.155G |
|   hid.enc.5.block                |   5.332M               |   12.767G  |
|    hid.enc.5.block.layer_scale_1 |    (512,)              |            |
|    hid.enc.5.block.layer_scale_2 |    (512,)              |            |
|    hid.enc.5.block.norm1         |    1.024K              |    2.458M  |
|    hid.enc.5.block.attn          |    1.09M               |    2.608G  |
|    hid.enc.5.block.norm2         |    1.024K              |    2.458M  |
|    hid.enc.5.block.mlp           |    4.24M               |    10.155G |
|   hid.enc.6.block                |   5.332M               |   12.767G  |
|    hid.enc.6.block.layer_scale_1 |    (512,)              |            |
|    hid.enc.6.block.layer_scale_2 |    (512,)              |            |
|    hid.enc.6.block.norm1         |    1.024K              |    2.458M  |
|    hid.enc.6.block.attn          |    1.09M               |    2.608G  |
|    hid.enc.6.block.norm2         |    1.024K              |    2.458M  |
|    hid.enc.6.block.mlp           |    4.24M               |    10.155G |
|   hid.enc.7                      |   5.694M               |   13.632G  |
|    hid.enc.7.block               |    5.332M              |    12.767G |
|    hid.enc.7.reduction           |    0.361M              |    0.865G  |
--------------------------------------------------------------------------------

